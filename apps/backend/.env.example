# DSPy / LiteLLM Configuration
# The model name should follow the LiteLLM provider prefix format (e.g., openai/..., openrouter/..., anthropic/...)
DSPY_DEFAULT_MODEL=openai/local-model

# --- Provider Specific Configuration ---
# LiteLLM automatically picks up variables based on the model prefix.

# For OpenAI:
# OPENAI_API_KEY=your-key-here

# OPENAI_API_BASE=http://localhost:8080/v1 use for Open AI Compatible API

# For OpenRouter:
# OPENROUTER_API_KEY=your-key-here

# For Anthropic:
# ANTHROPIC_API_KEY=your-key-here

# For Azure:
# AZURE_API_KEY=your-key-here
# AZURE_API_BASE=your-endpoint-here
# AZURE_API_VERSION=your-version-here
